# _Robots in Disguise_: The Foundation Models Reading Group

Public repo for The Alan Turing Institute's reading group on foundation models as part of the activities of Foundational AI theme.

If you're based at the Turing, follow `#robots-in-disguise` on the Turing Slack for the most recent updates.

**To see all the slides and reading materials for previous sessions, see the [archive](PREVIOUS.md).**

Note that this originated from the [Research Engineering Team](https://www.turing.ac.uk/research-engineering)'s reading group on Transformers.

## Overview

The group meets every <b>week on Mondays at 11-12</b>. Everyone is welcome to join! If you have any questions email [Ryan](mailto:rchan@turing.ac.uk) or [Fede](mailto:fnanni@turing.ac.uk) and remember to go through our [Code of Conduct](CodeOfConduct.md) before joining.

Please add suggestions and emoji preferences to the [list of proposed topics](https://hackmd.io/4zHl_1G6Se-yumHTN48dqg?both) on HackMD.

## Upcoming Schedule

|Date | Topic | Room | Lead |
| --- | ----- | ---- | ---- |
| [20/11/23](#201123) | Research at Turing: Transformers for coding/software engineering | Mae Jemison | [Anastasiia Grishina](https://www.turing.ac.uk/people/enrichment-students/anastasiia-grishina) |
| [27/11/23](#271123) | Discussion: Uncensored LLMs, use cases, pros/cons, and the ethics of them | David Blackwell | [Aoife Hughes](https://aoifehughes.github.io/) |
| [04/12/23](#041223) | Discussion: Best Practice for Responsible Foundation Models â€“ What Should Developers Do and How You Can Help | Ursula Franklin | [Carolyn Ashurst](https://www.turing.ac.uk/people/turing-research-fellows/carolyn-ashurst) |
| [11/12/23](#111223) | Technical: Stable Diffusion | David Blackwell | [Edmund Dable-Heath](https://github.com/eddableheath) |
| [08/01/24](#080124) | Discussion: Benchmarking AI applications on GPUs | David Blackwell | [Tomas Lazauskas](https://github.com/tomaslaz), [David Llewellyn-Jones](https://github.com/llewelld) |
| [15/01/24](#150124) | Technical: Retentive Networks | David Blackwell | Ed Gunn |
| [22/01/24](#220124) | Research at Turing: Spatial Graph Patterning of Filamentous Structures | David Blackwell | [Kristina Ulicna](https://www.turing.ac.uk/people/research-associates/kristina-ulicna)|
| [29/01/24](#290124) | Technical: Quantisation | David Blackwell | [Tom Davies](tomogwen), [Tarek Allam](https://tallamjr.github.io/) |
| [05/02/24](#050224) | Discussion: Existential Risk of AI? | David Blackwell | [Levan Bokeria](https://www.turing.ac.uk/people/research-engineering/levan-bokeria) |
| [12/02/24](#120224) | Technical: Mechanistic interpretability | David Blackwell | [Praveen Selvaraj](https://github.com/pravsels) |
| [19/02/24](#190224) | Research at Turing: Longitudinal NLP | David Blackwell | [Jenny Chim](https://j-chim.github.io/), [Talia Tseriotou](https://github.com/ttseriotou) |
| [26/02/24](#260224) | Research at Turing: Machine translation quality estimation | David Blackwell | [Radka Jersakova](https://www.turing.ac.uk/people/researchers/radka-jersakova), [Jo Knight](https://www.turing.ac.uk/people/researchers/joanna-knight) |
| [04/03/24](#040324) | Invited Talk: What is the Hugging Face Hub & An introduction to computer vision with ðŸ¤— transformers  | David Blackwell | Daniel Van Strien and Amy Sartran |
| [11/03/24](#110324) | Research at Turing: Applying Vision Transformers in Neuroscience | David Blackwell | [Bryan Li](https://bryanli.io/) |
| [18/03/24](#180324) | TBC | David Blackwell | TBC |
| [25/03/24](#250324) | TBC | David Blackwell | TBC |
| [08/04/24](#080424) | TBC: Research at Turing | David Blackwell | TBC: Marek Strong |

# Material for sessions

## 20/11/23
### Transformers for coding/software engineering

**Main**
- Encoders for code classification: [The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification](https://arxiv.org/abs/2305.04940)

**Extra**
- [Large Language Models for Software Engineering: Survey and Open Problems](https://arxiv.org/abs/2310.03533)
- [A Systematic Evaluation of Large Language Models of Code](https://arxiv.org/abs/2202.13169)
- [Automated Program Repair in the Era of Large Pre-trained Language Models](https://lingming.cs.illinois.edu/publications/icse2023a.pdf)

## 27/11/23
### Uncensored LLMs

## 04/12/23
### Guidance for Safe Foundation Model Deployment

## 11/12/23
### Stable Diffusion

The main stable/latent diffusion paper [is here](https://arxiv.org/pdf/2112.10752.pdf).

## 08/01/24
### tbc

## 15/01/24
### Retentive Networks

**Main**
- [Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621)

## 22/01/24
### TBC

## 29/01/24
### Quantisation

## 05/02/24
### Toxicity

## 12/02/24
### TBC

## 19/02/24
### Longitudinal NLP

**Main**
- [BitNet: Scaling 1-bit Transformers for Large Language Models](https://arxiv.org/abs/2310.11453)

## 26/02/24
### Machine Translation Quality Estimation

## 04/03/24
### HuggingFace Talks

## 11/03/24
### Applying Vision Transformers in Neuroscience

## 18/03/24
### TBC

## 25/03/24
### TBC

## 08/04/24
### TBC

## Miscellaneous

### Tokenizers and Huggingface tutorial

**Main**
- [Huggingface Tokenizer tutorial](https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt)
- [Huggingface `transformers` course](https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt)
