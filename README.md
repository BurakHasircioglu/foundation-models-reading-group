# _Robots in Disguise_: The Foundation Models Reading Group

Public repo for The Alan Turing Institute's reading group on foundation models as part of the activities of Foundational AI theme.

If you're based at the Turing, follow `#robots-in-disguise` on the Turing Slack for the most recent updates.

**To see all the slides and reading materials for previous sessions, see the [archive](PREVIOUS.md).**

Note that this originated from the [Research Engineering Team](https://www.turing.ac.uk/research-engineering)'s reading group on Transformers.

## Overview

The group meets every <b>week on Mondays at 11-12</b>. Everyone is welcome to join! If you have any questions email [Ryan](mailto:rchan@turing.ac.uk) or [Fede](mailto:fnanni@turing.ac.uk) and remember to go through our [Code of Conduct](CodeOfConduct.md) before joining.

Please **get in touch** if you would like to give a talk (either about your research or a topic you think is relevant to the reading group) add suggestions and emoji preferences to the [list of proposed topics](https://hackmd.io/4zHl_1G6Se-yumHTN48dqg?both) on HackMD!

## Upcoming Schedule

|Date | Topic | Room | Lead |
| --- | ----- | ---- | ---- |
| [08/01/24](#080124) | Discussion: Benchmarking AI applications on GPUs | David Blackwell | [Tomas Lazauskas](https://github.com/tomaslaz), [David Llewellyn-Jones](https://github.com/llewelld) |
| [15/01/24](#150124) | Technical: Retentive Networks | David Blackwell | Ed Gunn |
| [22/01/24](#220124) | Research at Turing: Spatial Graph Patterning of Filamentous Structures | David Blackwell | [Kristina Ulicna](https://www.turing.ac.uk/people/research-associates/kristina-ulicna)|
| [29/01/24](#290124) | Technical: Quantisation | David Blackwell | [Tom Davies](tomogwen), [Tarek Allam](https://tallamjr.github.io/) |
| [05/02/24](#050224) | Discussion: Existential Risk of AI? | David Blackwell | [Levan Bokeria](https://www.turing.ac.uk/people/research-engineering/levan-bokeria) |
| [12/02/24](#120224) | Technical: Mechanistic interpretability | David Blackwell | [Praveen Selvaraj](https://github.com/pravsels) |
| [19/02/24](#190224) | Research at Turing: Longitudinal NLP | David Blackwell | [Jenny Chim](https://j-chim.github.io/), [Talia Tseriotou](https://github.com/ttseriotou) |
| [26/02/24](#260224) | Research at Turing: Machine translation quality estimation | David Blackwell | [Radka Jersakova](https://www.turing.ac.uk/people/researchers/radka-jersakova), [Jo Knight](https://www.turing.ac.uk/people/researchers/joanna-knight) |
| [04/03/24](#040324) | Invited Talk: What is the Hugging Face Hub & An introduction to computer vision with ðŸ¤— transformers  | David Blackwell | Daniel Van Strien and Amy Sartran |
| [11/03/24](#110324) | Research at Turing: Applying Vision Transformers in Neuroscience | David Blackwell | [Bryan Li](https://bryanli.io/) |
| [18/03/24](#180324) | Research at Turing: Not even a Chinese Room: evaluating LLMs on code simulation | David Blackwell | [Emanuele La Malfa](https://www.cs.ox.ac.uk/people/emanuele.lamalfa/) |
| [25/03/24](#250324) | Research at Turing: Learn how to learn and distil during learning - Using meta-learning and second order optimisation to prune the model | David Blackwell | Yilei Liang |
| [08/04/24](#080424) | Research at Turing: TBC | David Blackwell | Marek Strong |
| [15/04/24](#150424) | Discussion: Towards openness beyond open access: case study on BigCode LLM governance | David Blackwell | [Jennifer Ding](https://www.turing.ac.uk/people/business-team/jennifer-ding) |
| [22/04/24](#220424) | Discussion: Uncensored LLMs, use cases, pros/cons, and the ethics of them | David Blackwell | [Aoife Hughes](https://github.com/AoifeHughes) |
| [29/04/24)(#290424) | Invited Talk: How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions | David Blackwell | [Lorenzo Pacchiardi](http://www.lorenzopacchiardi.me/) |

# Material for sessions

## 08/01/24
### Benchmarking AI applications on GPUs

## 15/01/24
### Retentive Networks

**Main**
- [Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621)

## 22/01/24
### Spatial Graph Patterning of Filamentous Structures

## 29/01/24
### Quantisation

## 05/02/24
### Existential Risk of AI?

## 12/02/24
### Mechanistic interpretability

## 19/02/24
### Longitudinal NLP

**Main**
- [BitNet: Scaling 1-bit Transformers for Large Language Models](https://arxiv.org/abs/2310.11453)

## 26/02/24
### Machine Translation Quality Estimation

## 04/03/24
### What is the Hugging Face Hub & An introduction to computer vision with ðŸ¤— transformers

## 11/03/24
### Applying Vision Transformers in Neuroscience

## 18/03/24
### Not even a Chinese Room: evaluating LLMs on code simulation

## 25/03/24
### Learn how to learn and distil during learning - Using meta-learning and second order optimisation to prune the model

## 08/04/24
### TBC

## 15/04/24
### Towards openness beyond open access: case study on BigCode LLM governance 

## 22/04/24
### Uncensored LLMs, use cases, pros/cons, and the ethics of them

## 29/04/24
### How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions

**Main**
- [How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions](https://arxiv.org/abs/2309.15840)

## Miscellaneous

### Tokenizers and Huggingface tutorial

**Main**
- [Huggingface Tokenizer tutorial](https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt)
- [Huggingface `transformers` course](https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt)
